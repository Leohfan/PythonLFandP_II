{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.1 字符串函数操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）大小写转换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部大写格式：\tHARRY POTTER\n",
      "全部小写格式：\tharry potter\n",
      "标题格式：\tHarry Potter\n"
     ]
    }
   ],
   "source": [
    "user_name = \"Harry POTTER\"\n",
    "\n",
    "# 1. 将姓名转换为全部大写\n",
    "name_upper = user_name.upper()\n",
    "print(f\"全部大写格式：\\t{name_upper}\")\n",
    "\n",
    "# 2. 将姓名转换为全部小写\n",
    "name_lower = user_name.lower()\n",
    "print(f\"全部小写格式：\\t{name_lower}\")\n",
    "\n",
    "# 3. 将姓名每个单词的首字母大写\n",
    "name_title = user_name.title()\n",
    "print(f\"标题格式：\\t{name_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abc Def Ghi\n",
      "ABC DEF GHI\n",
      "abc def ghi\n"
     ]
    }
   ],
   "source": [
    "s1 = \"abc def ghi\"         \n",
    "print(s1.title())       #将字符串s1中每个单词首字母转换为大写\n",
    "print(s1.upper())       #将字符串s1中每个字母改为全部大写\n",
    "s2 = \"ABC DEF GHI\"\n",
    "print(s2.lower())        #将字符串s2中每个单词改为全部小写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Hello world!\")                 #计算字符串\"Hello world!\"所包含的字符数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）空白字符处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 lstrip() 删除左侧空白: 'I love the world!   '\n",
      "使用 rstrip() 删除右侧空白: '  I love the world!'\n",
      "使用 strip() 删除两侧空白: 'I love the world!'\n",
      "原字符串 text 仍然保留空白: '  I love the world!   '\n"
     ]
    }
   ],
   "source": [
    "# 示例字符串\n",
    "text = \"  I love the world!   \"\n",
    "\n",
    "# 删除字符串左侧的空白\n",
    "left_trimmed = text.lstrip()\n",
    "print(f\"使用 lstrip() 删除左侧空白: '{left_trimmed}'\")\n",
    "\n",
    "# 删除字符串右侧的空白\n",
    "right_trimmed = text.rstrip()\n",
    "print(f\"使用 rstrip() 删除右侧空白: '{right_trimmed}'\")\n",
    "\n",
    "# 删除字符串两侧的空白\n",
    "fully_trimmed = text.strip()\n",
    "print(f\"使用 strip() 删除两侧空白: '{fully_trimmed}'\")\n",
    "\n",
    "print(f\"原字符串 text 仍然保留空白: '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去除空白后的字符串 text: 'I love the world!'\n"
     ]
    }
   ],
   "source": [
    "text = text.strip()\n",
    "print(f\"去除空白后的字符串 text: '{text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love the world!\n",
      "  I love the world!\n",
      "I love the world!  \n"
     ]
    }
   ],
   "source": [
    "s = \"  I love the world!  \"           #创建一个新的字符串并命名为s\n",
    "print(s.strip())                      #删除字符串s开头和末尾处的空白\n",
    "print(s.rstrip())                     #删除字符串s末尾处的空白\n",
    "print(s.lstrip())                     #删除字符串s开头处的空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）查找与替换函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Python'第一次出现的位置: 18\n",
      "'Python'在字符串中出现的次数: 2\n",
      "字符串是否以'Hello'开始: True\n",
      "字符串是否以'fun!'结束: True\n",
      "替换'Python'为'Java'后的字符串: Hello, welcome to Java programming. Java is fun!\n"
     ]
    }
   ],
   "source": [
    "# 原字符串\n",
    "text = \"Hello, welcome to Python programming. Python is fun!\"\n",
    "\n",
    "# 查找子字符串的位置\n",
    "position = text.find(\"Python\")\n",
    "print(f\"'Python'第一次出现的位置: {position}\")\n",
    "\n",
    "# 统计子字符串出现的次数\n",
    "count = text.count(\"Python\")\n",
    "print(f\"'Python'在字符串中出现的次数: {count}\")\n",
    "\n",
    "# 检查字符串是否以某个前缀开始\n",
    "is_start = text.startswith(\"Hello\")\n",
    "print(f\"字符串是否以'Hello'开始: {is_start}\")\n",
    "\n",
    "# 检查字符串是否以某个后缀结束\n",
    "is_end = text.endswith(\"fun!\")\n",
    "print(f\"字符串是否以'fun!'结束: {is_end}\")\n",
    "\n",
    "# 替换指定的子字符串\n",
    "replaced_text = text.replace(\"Python\", \"Java\")\n",
    "print(f\"替换'Python'为'Java'后的字符串: {replaced_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thwas was an apple, and thwas was really big!\n",
      "thwas was an apple, and thwas is really big!\n"
     ]
    }
   ],
   "source": [
    "s = \"this is an apple, and this is really big!\"\n",
    "print (s.replace(\"is\",\"was\"))         #将字符串s中所有的is都替换成was\n",
    "print (s.replace(\"is\", \"was\", 3))     #将字符串s中前三个is都替换成was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thwas was an apple, and thwas was really big!\n"
     ]
    }
   ],
   "source": [
    "s = \"this is an apple, and this is really big!\"\n",
    "print (s.replace(\"is\", \"was\", 10))   #将字符串se中前十个is都替换成was"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）分割与连接函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', 'welcome', 'to', 'Python', 'programming.']\n",
      "['Hello', ' welcome to Python programming.']\n",
      "['Hello,', 'welcome', 'to Python programming.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, welcome to Python programming.\"\n",
    "# 默认按空格分割\n",
    "words = text.split()\n",
    "print(words)  # 输出: ['Hello,', 'welcome', 'to', 'Python', 'programming.']\n",
    "\n",
    "# 指定分隔符 \",\"\n",
    "words = text.split(\",\")\n",
    "print(words)  # 输出: ['Hello', ' welcome to Python programming.']\n",
    "\n",
    "# 限制分割次数\n",
    "words = text.split(\" \", 2)\n",
    "print(words)  # 输出: ['Hello,', 'welcome', 'to Python programming.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jonny,Nice', 'to', 'meet', 'you!']\n",
      "['Jonny', 'Nice to meet you!']\n",
      "['Jonny,Nice', 'to', 'meet', 'you!']\n"
     ]
    }
   ],
   "source": [
    "s = \"Jonny,Nice to meet you!\"      #创建一个新的字符串并命名为s\n",
    "print(s.split(' '))                #以空格作为分隔符拆分字符串s\n",
    "print(s.split(','))                #以逗号作为分隔符拆分字符串s\n",
    "print(s.split())                   #不指定分隔符拆分字符串s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome to Python programming.\n",
      "Hello,welcome,to,Python,programming.\n"
     ]
    }
   ],
   "source": [
    "words = ['Hello', 'welcome', 'to', 'Python', 'programming.']\n",
    "# 使用空格连接列表中的单词\n",
    "sentence = \" \".join(words)\n",
    "print(sentence)  # 输出: Hello welcome to Python programming.\n",
    "\n",
    "# 使用逗号连接\n",
    "csv_format = \",\".join(words)\n",
    "print(csv_format)  # 输出: Hello,welcome,to,Python,programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amy is 18 years old.\n"
     ]
    }
   ],
   "source": [
    "name = \"Amy\"\n",
    "age = 18\n",
    "info = name + \" is \" + str(age) +\" years old.\"\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.2 字符串的索引和切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "P\n",
      "n\n",
      "!\n",
      "y\n",
      "e\n",
      "第一个字符：H，最后一个字符：!\n"
     ]
    }
   ],
   "source": [
    "# 定义字符串\n",
    "text = \"Hello, Python!\"\n",
    "\n",
    "# 正向索引访问\n",
    "print(text[0])   # 输出 'H'，即第一个字符\n",
    "print(text[7])   # 输出 'P'，即第八个字符\n",
    "print(text[12])  # 输出 'n'，即第十三个字符\n",
    "\n",
    "# 负向索引访问\n",
    "print(text[-1])  # 输出 '!'，即最后一个字符\n",
    "print(text[-6])  # 输出 'P'，从末尾反向第六个字符\n",
    "print(text[-13]) # 输出 'H'，与正向索引0的结果一致\n",
    "\n",
    "# 结合正向与负向索引访问字符\n",
    "print(f\"第一个字符：{text[0]}，最后一个字符：{text[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS='literalstring'\n",
    "LS[0],LS[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "15\n",
      "7\n",
      "未找到 'Java'\n"
     ]
    }
   ],
   "source": [
    "# 定义字符串\n",
    "text = \"Hello, Python! Hello, World!\"\n",
    "\n",
    "# 使用 find 和 rfind 查找子字符串\n",
    "print(text.find(\"Hello\"))   # 输出 0，'Hello' 第一次出现的位置\n",
    "print(text.rfind(\"Hello\"))  # 输出 15，'Hello' 最后一次出现的位置\n",
    "\n",
    "# 使用 index 和 rindex 查找子字符串\n",
    "print(text.index(\"Python\")) # 输出 7，'Python' 的起始位置\n",
    "try:\n",
    "    print(text.index(\"Java\")) # 若未找到，抛出 ValueError 异常\n",
    "except ValueError:\n",
    "    print(\"未找到 'Java'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS='literalstring'\n",
    "LS.find(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello\n",
      "Python!\n",
      "Python\n",
      "Hlo yhn\n",
      "!nohtyP ,olleH\n",
      "Hello, Python!\n",
      "Python!\n"
     ]
    }
   ],
   "source": [
    "# 示例字符串\n",
    "text = \"Hello, Python!\"\n",
    "\n",
    "# 1. 提取子字符串\n",
    "# 从第1个字符开始，到第5个字符结束（不包含第5个字符）\n",
    "print(text[0:5])  # 输出: 'Hello'\n",
    "\n",
    "# 2. 使用省略的开始或结束位置\n",
    "# 从起始位置到第5个字符结束\n",
    "print(text[:5])   # 输出: 'Hello'\n",
    "# 从第7个字符开始到字符串末尾\n",
    "print(text[7:])   # 输出: 'Python!'\n",
    "\n",
    "# 3. 使用负索引\n",
    "# 从倒数第7个字符开始，到倒数第1个字符结束（不包含最后一个字符）\n",
    "print(text[-7:-1])  # 输出: 'Python'\n",
    "\n",
    "# 4. 步长切片\n",
    "# 每隔一个字符提取一次\n",
    "print(text[::2])  # 输出: 'Hlo yhn'\n",
    "# 反向提取整个字符串\n",
    "print(text[::-1])  # 输出: '!nohtyP ,olleH'\n",
    "\n",
    "# 5. 省略开始、结束和步长\n",
    "# 默认提取整个字符串\n",
    "print(text[:])    # 输出: 'Hello, Python!'\n",
    "\n",
    "# 6. 尝试切片的结束索引超出字符串长度\n",
    "# Python自动处理至字符串结尾，程序不会报错\n",
    "print(text[7:50])  # 输出: 'Python!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literalstring\n",
      "teralstring\n",
      "literals\n",
      "terals\n",
      "trl\n",
      "srn\n",
      "teralstring\n"
     ]
    }
   ],
   "source": [
    "LS='literalstring'      #创建一个字符串并命名为LS\n",
    "print(LS[:])             #输出字符串LS\n",
    "print(LS[2:])            #从偏移量2提取到字符串最后（不包含第2个字母）\n",
    "print(LS[:8])            #从字符串开始提取到偏移量8（包含第8个字母）\n",
    "print(LS[2:8])           #从偏移量2（不包含2）提取至偏移量8（包含8）\n",
    "print(LS[2:8:2])         #从偏移量2（不包含2）每2个字母提取至偏移量8（包含8）\n",
    "print(LS[-6:-1:2])      #从倒数第6个（包含倒数第6）每2个提取至倒数第1个（不包倒数第1）\n",
    "print(LS[2:30])       #从偏移量10（不包含10）提取至偏移量30（包含30），索引过大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 正则表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "贪婪匹配 o.*e 结果: ['one1two2three']\n",
      "贪婪匹配 o.+e 结果: ['one1two2three']\n",
      "贪婪匹配 o.{m,n}e 结果: ['one', 'o2three']\n",
      "懒惰匹配 o.*?e 结果: ['one', 'o2thre']\n",
      "懒惰匹配 o.+?e 结果: ['one', 'o2thre']\n",
      "懒惰匹配 o.{m,n}?e 结果: ['one', 'o2thre']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 懒惰匹配\n",
    "text = \"one1two2three3four4\"\n",
    "pattern = r\"o.*e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(\"贪婪匹配 o.*e 结果:\", matches)\n",
    "pattern = r\"o.+e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(\"贪婪匹配 o.+e 结果:\", matches)\n",
    "pattern = r\"o.{1,5}e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(\"贪婪匹配 o.{m,n}e 结果:\", matches)\n",
    "\n",
    "pattern = r\"o.*?e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(\"懒惰匹配 o.*?e 结果:\", matches)\n",
    "pattern = r\"o.+?e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(\"懒惰匹配 o.+?e 结果:\", matches)\n",
    "pattern = r\"o.{1,5}?e\"\n",
    "matches = re.findall(pattern, text)\n",
    "print(\"懒惰匹配 o.{m,n}?e 结果:\", matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始字符串: one1two2three3four4\n",
      "懒惰匹配: o.*?e\n",
      "懒惰匹配结果: ['one', 'o2thre']\n",
      "贪婪匹配: o.*e\n",
      "贪婪匹配结果: ['one1two2three']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "str1 = \"one1two2three3four4\"\n",
    "print(\"原始字符串:\",str1)\n",
    "regexL = \"o.*?e\"\n",
    "print(\"懒惰匹配:\",regexL) \n",
    "listL = re.findall(regexL,str1)      # 懒惰匹配\n",
    "print(\"懒惰匹配结果:\",listL)\n",
    "regexT = \"o.*e\"\n",
    "print(\"贪婪匹配:\",regexT)\n",
    "listT = re.findall(regexT,str1)      # 贪婪匹配\n",
    "print(\"贪婪匹配结果:\",listT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.3 正则表达式应用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='one'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.match('one', 'one two three'))\n",
    "print(re.match('three', 'one two three'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n"
     ]
    }
   ],
   "source": [
    "match=re.match('one', 'one two three')\n",
    "print(match.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\d+\"\n",
    "search = re.search(pattern, \"abc123xyz\")\n",
    "if search:\n",
    "    print(search.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "search =re.search('one', 'one two three')\n",
    "print(search.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.match: None\n",
      "re.seartch: dogs\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = \"Cats are smarter than dogs\";\n",
    "match = re.match('dogs',s)\n",
    "if match:\n",
    "   print (\"re.match:\",match.group())\n",
    "else:\n",
    "   print (\"re.match: None\")\n",
    " \n",
    "search = re.search('dogs',s)\n",
    "if search:\n",
    "   print (\"re.seartch:\",search.group())\n",
    "else:\n",
    "   print (\"re.seartch: None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', '456']\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\\d+\"  # 匹配所有的数字\n",
    "string = \"abc123xyz456\"\n",
    "result = re.findall(pattern, string)\n",
    "print(result)  # 输出：['123', '456']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "456\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r\"\\d+\"  # 匹配所有的数字\n",
    "string = \"abc123xyz456\"\n",
    "result = re.finditer(pattern, string)\n",
    "for match in result:\n",
    "    print(match.group())  # 输出：123 456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: No match at the start of the string.\n",
      "Search: Found 2023 at position (9, 13)\n",
      "Findall: All matches found - ['2023', '2024', '123']\n",
      "Finditer:\n",
      "  Found '2023' at position (9, 13)\n",
      "  Found '2024' at position (29, 33)\n",
      "  Found '123' at position (39, 42)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 使用 compile 创建正则表达式对象\n",
    "pattern = re.compile(r'\\d+')\n",
    "\n",
    "# 待处理字符串\n",
    "text = \"The year 2023 is followed by 2024, and 123abc is another example.\"\n",
    "\n",
    "# 1. 使用 match() 方法：尝试从字符串开头进行匹配\n",
    "match_result = pattern.match(text)\n",
    "if match_result:\n",
    "    print(f\"Match: {match_result.group()}\")\n",
    "else:\n",
    "    print(\"Match: No match at the start of the string.\")\n",
    "\n",
    "# 2. 使用 search() 方法：在整个字符串中查找第一个匹配\n",
    "search_result = pattern.search(text)\n",
    "if search_result:\n",
    "    print(f\"Search: Found {search_result.group()} at position {search_result.span()}\")\n",
    "\n",
    "# 3. 使用 findall() 方法：找到字符串中所有符合模式的部分\n",
    "findall_result = pattern.findall(text)\n",
    "print(f\"Findall: All matches found - {findall_result}\")\n",
    "\n",
    "# 4. 使用 finditer() 方法：返回匹配的迭代器对象\n",
    "finditer_result = pattern.finditer(text)\n",
    "print(\"Finditer:\")\n",
    "for match in finditer_result:\n",
    "    print(f\"  Found '{match.group()}' at position {match.span()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order X shipped on X-X-X.\n",
      "Order X shipped on X-10-15.\n"
     ]
    }
   ],
   "source": [
    "result = re.sub(r'\\d+', 'X', 'Order 123 shipped on 2024-10-15.')\n",
    "print(result)\n",
    "result = re.sub(r'\\d+', 'X', 'Order 123 shipped on 2024-10-15.', count=2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: 20, Quantity: 6.\n"
     ]
    }
   ],
   "source": [
    "def repl_func(match):\n",
    "    return str(int(match.group()) * 2)\n",
    "\n",
    "result = re.sub(r'\\d+', repl_func, 'Price: 10, Quantity: 3.')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of 7 and 9 is 16.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "s = \"the sum of 7 and 9 is 15.\"\n",
    "print(re.sub('15', '16', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of 14 and 18is 32.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def double(matched):\n",
    "    value = int(matched.group('value'))# 将匹配的数字乘以2\n",
    "    return str(value*2)\n",
    "s = 'the sum of 7 and 9is 16.'\n",
    "print(re.sub('(?P<value>\\d+)', double, s)) #命名一个名字为value的组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4']\n",
      "['1', '2']\n",
      "['1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "s = 'one1two2three3four4'\n",
    "pattern = re.compile('\\d+')      # 查找数字，使用compile 预编译后使用 findall\n",
    "\n",
    "print(pattern.findall(s))\n",
    "print(pattern.findall(s,0,10))   # 限定进行匹配字符串长度\n",
    "print(re.findall('\\d+', s))      # 不使用 compile 直接使用re.findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'two', 'three', 'four', '']\n",
      "['one1two2three3four4']\n",
      "['one', 'two2three3four4']\n"
     ]
    }
   ],
   "source": [
    "s = 'one1two2three3four4'\n",
    "print(re.split('\\d+', s))    # 按照数字切分\n",
    "print(re.split('a', s, 1))   # a 匹配不到 返回包含自身的列表\n",
    "print(re.split('\\d+', s, 1)) # maxsplit 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ' world', ' How are you', '']\n",
      "['Hello', ',', ' world', '!', ' How are you', '?', '']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(r'[,.!?]', 'Hello, world! How are you?')\n",
    "print(result)  # 按标点符号分割\n",
    "result = re.split(r'([,.!?])', 'Hello, world! How are you?')\n",
    "print(result)  # 使用分组，分割后的结果会保留分隔符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example@domain.com\n",
      "example\n",
      "domain\n",
      "com\n",
      "(9, 27)\n",
      "(9, 16)\n",
      "(17, 23)\n",
      "(24, 27)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = r\"(\\w+)@(\\w+)\\.(\\w+)\"\n",
    "string = \"contact: example@domain.com\"\n",
    "\n",
    "match = re.search(pattern, string)\n",
    "\n",
    "print(match.group())      # 输出：example@domain.com（整个匹配）\n",
    "print(match.group(1))     # 输出：example（第 1 个捕获组）\n",
    "print(match.group(2))     # 输出：domain（第 2 个捕获组）\n",
    "print(match.group(3))     # 输出：com（第 3 个捕获组）\n",
    "\n",
    "print(match.span())      # 输出：(9, 25)（整个匹配的起止位置）\n",
    "print(match.span(1))     # 输出：(9, 16)（第 1 个捕获组的起止位置）\n",
    "print(match.span(2))     # 输出：(17, 23)（第 2 个捕获组的起止位置）\n",
    "print(match.span(3))     # 输出：(24, 27)（第 3 个捕获组的起止位置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 11), match='Hello wide '>\n",
      "Hello wide \n",
      "(0, 11)\n",
      "('Hello', 'wide')\n",
      "Hello\n",
      "(0, 5)\n",
      "0\n",
      "5\n",
      "wide\n",
      "(6, 10)\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile('([a-z]+) ([a-z]+) ', re.I)   # re.I 表示忽略大小写\n",
    "m = pattern.match('Hello wide wide world')\n",
    "print(m)                             # 匹配成功，返回一个 Match 对象\n",
    "print(m.group())                     # 返回匹配成功的整个子串\n",
    "print(m.span())                      # 返回匹配成功的整个子串的索引\n",
    "print(m.groups())                    # 等价于 (m.group(1), m.group(2), ...) \n",
    "print(m.group(1))                    # 返回第一个分组匹配成功的子串\n",
    "print(m.span(1))                     # 返回第一个分组匹配成功的子串的索引\n",
    "print(m.start(1))                    # 返回第一个分组匹配成功的子串的开始位置\n",
    "print(m.end(1))                      # 返回第一个分组匹配成功的子串的结束位置\n",
    "print(m.group(2))                    # 返回第二个分组匹配成功的子串\n",
    "print(m.span(2))                     # 返回第二个分组匹配成功的子串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.4 正则表达式的修饰符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.S使.匹配包括换行在内的所有字符 [('great', ' \\n        object-oriented,\\n        ', 'inter')]\n",
      "re.I不区分大小写: ['And interactive ']\n",
      "re.M多行匹配 ['interpreted, ', 'interactive ']\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\" Python is a great \n",
    "        object-oriented,\n",
    "        interpreted, \n",
    "        And interactive \n",
    "        programming language. \"\"\"\n",
    "re1= re.findall(r'(great)(.*?)(inter)',s,re.S)\n",
    "print(\"re.S使.匹配包括换行在内的所有字符\",re1)\n",
    "re2 = re.findall(r'(and.*)',s,re.I)\n",
    "print(\"re.I不区分大小写:\",re2)\n",
    "re3 = re.findall(r'(inter.*)',s,re.M)\n",
    "print(\"re.M多行匹配\",re3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.456\n",
      "123.456\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "patt_a = re.compile(r\"\"\"\\d +  # the integral part\n",
    "                   \\.    # the decimal point\n",
    "                   \\d *  # some fractional digits\"\"\", re.X)\n",
    "patt_b = re.compile(r\"\\d+\\.\\d*\")\n",
    "print(patt_a.match(\"123.456\").group())\n",
    "print(patt_b.match(\"123.456\").group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(r\"\"\"\n",
    "            # 匹配数字或字母\n",
    "            /d+\n",
    "            # 数字\n",
    "            | \n",
    "            [a-zA-Z]+\n",
    "            # 字母\n",
    "            \"\"\", re.X)\n",
    "result = pattern.match('abc012')\n",
    "print(result.group())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.3.5 正则表达式的应用案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户名： wer233 匹配!\n",
      "用户名： _34txial 匹配!\n",
      "程序完成！\n"
     ]
    }
   ],
   "source": [
    "# 用户名匹配\n",
    "# 用户名只能包含字母、数字和下划线，且长度限制在 3 到 15 个字符之间。\n",
    "import re\n",
    "pattern='^[A-Za-z0-9_]{3,15}$'\n",
    "username=input('请输入用户名（quit退出）：')\n",
    "while(username != 'quit'):\n",
    "    result=re.match(pattern,username)\n",
    "    if result:\n",
    "        print('用户名：',username,'匹配!')\n",
    "    else:\n",
    "        print('用户名：',username,'不匹配!')\n",
    "    username=input('请输入用户名（quit退出）：')\n",
    "print('程序完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "密码： weri374 不匹配!\n",
      "密码： zafrie12W 匹配!\n",
      "程序完成！\n"
     ]
    }
   ],
   "source": [
    "# 用户密码匹配\n",
    "# 要求密码长度必须为 8 到 20 个字符，且至少包含一个大写字母、一个小写字母和一个数字。\n",
    "import re\n",
    "pattern='^(?=.*[A-Z])(?=.*[a-z])(?=.*\\d)[A-Za-z\\d]{8,20}$'\n",
    "password=input('请输入密码(quit退出):')\n",
    "while(password != 'quit'):\n",
    "    result=re.match(pattern,password)\n",
    "    if result:\n",
    "        print('密码：',password,'匹配!')\n",
    "    else:\n",
    "        print('密码：',password,'不匹配!')\n",
    "    password=input('密码(quit退出):')\n",
    "\n",
    "print('程序完成！')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.example.com\t is a valid URL.\n",
      "https://www.example.net\t is a valid URL.\n",
      "www.example.org\t is a valid URL.\n",
      "example.com\t is not a valid URL.\n",
      "http://example\t is not a valid URL.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# URL正则表达式\n",
    "url_pattern = r'^(http://|https://)?(www\\.)[a-zA-Z0-9-]+\\.[a-zA-Z]{2,6}$'\n",
    "\n",
    "# 测试URL\n",
    "test_urls = [\n",
    "    'http://www.example.com',\n",
    "    'https://www.example.net',\n",
    "    'www.example.org',\n",
    "    'example.com',  # 不符合正则表达式\n",
    "    'http://example',  # 不符合正则表达式\n",
    "]\n",
    "\n",
    "# 检验URL\n",
    "for url in test_urls:\n",
    "    if re.match(url_pattern, url):\n",
    "        print(f'{url}\\t is a valid URL.')\n",
    "    else:\n",
    "        print(f'{url}\\t is not a valid URL.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.abc123 不匹配\n",
      "http://www.abc123.cn 匹配\n",
      "http://www.abc123.com 匹配\n"
     ]
    }
   ],
   "source": [
    "#url匹配\n",
    "#URL可以分为两个部分，以常见的http协议的URL为例，\n",
    "#第一部分是协议部分即“http://”；\n",
    "#第二部分是域名，可以视为是一个以“www.”为开头的，中间为任意数字和字母的组合，\n",
    "#然后以“.com”、“.cn”、“.net”结尾的一个字符串\n",
    "import re\n",
    "pattern=r'^(http:)/{2}w{3}\\.[a-z0-9A-Z]+\\.(com|cn|net)'\n",
    "url1='http://www.abc123'\n",
    "url2='http://www.abc123.cn'\n",
    "url3='http://www.abc123.com'\n",
    "result1=re.match(pattern,url1)\n",
    "if result1:\n",
    "    print(url1, '匹配')\n",
    "else:\n",
    "    print(url1, '不匹配')\n",
    "result2=re.match(pattern,url2)\n",
    "if result2:\n",
    "    print(url2, '匹配')\n",
    "else:\n",
    "    print(url2, '不匹配')\n",
    "result3=re.match(pattern,url3)\n",
    "if result3:\n",
    "    print(url3, '匹配')\n",
    "else:\n",
    "    print(url3, '不匹配')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"example@example.com\" is a valid email address.\n",
      "\"user.name123@subdomain.example.co\" is not a valid email address.\n",
      "\"invalid@domain\" is not a valid email address.\n",
      "\"user@.com\" is not a valid email address.\n",
      "\"user@domain.c\" is not a valid email address.\n"
     ]
    }
   ],
   "source": [
    "#电子邮箱匹配\n",
    "import re\n",
    "email_pattern = r'^[a-zA-Z0-9_-]+@[a-zA-Z0-9-]+\\.[a-zA-Z]{2,6}$'\n",
    "\n",
    "# 测试邮箱\n",
    "test_emails = [\n",
    "    'example@example.com',\n",
    "    'user.name123@subdomain.example.co',\n",
    "    'invalid@domain',  # 不符合正则表达式\n",
    "    'user@.com',  # 不符合正则表达式\n",
    "    'user@domain.c',  # 不符合正则表达式\n",
    "]\n",
    "\n",
    "# 检验邮箱\n",
    "for email in test_emails:\n",
    "    if re.match(email_pattern, email):\n",
    "        print(f'\"{email}\" is a valid email address.')\n",
    "    else:\n",
    "        print(f'\"{email}\" is not a valid email address.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whuer123@123.com 匹配\n",
      "小明123@123.com 不匹配\n",
      "whuer123@12 不匹配\n"
     ]
    }
   ],
   "source": [
    "#电子邮箱匹配\n",
    "#通常由三部分组成，\n",
    "#第一部分是用户名，一般由任意数字和字母组成，并且允许使用“-”和“_”；\n",
    "#第二部分是分隔符“@”；\n",
    "#第三部分是邮箱服务器的域名如“xxx.com”。\n",
    "import re\n",
    "pattern='[a-zA-Z0-9_-]+@+[a-z0-9A-Z]+\\.(com|cn|net)'\n",
    "email1='whuer123@123.com'\n",
    "email2='小明123@123.com'\n",
    "email3='whuer123@12'\n",
    "\n",
    "result=re.match(pattern,email1)\n",
    "if result:\n",
    "    print(email1, '匹配')\n",
    "else:\n",
    "    print(email1, '不匹配')\n",
    "\n",
    "result=re.match(pattern,email2)\n",
    "if result:\n",
    "    print(email2, '匹配')\n",
    "else:\n",
    "    print(email2, '不匹配')\n",
    "result=re.match(pattern,email3)\n",
    "if result:\n",
    "    print(email3, '匹配')\n",
    "else:\n",
    "    print(email3, '不匹配')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正则表达式应用——缩写词扩充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma: A[a-z]+ B[a-z]+ C[a-z]+ \n",
      "Algriculture Bank China\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def expand_abbr(sen, abbr):\n",
    "    lenabbr = len(abbr)\n",
    "    ma = '' \n",
    "    for i in range(0, lenabbr):\n",
    "        ma += abbr[i] + \"[a-z]+\" + ' '\n",
    "    print('ma:', ma)\n",
    "    ma = ma.strip(' ')\n",
    "    p = re.search(ma, sen)\n",
    "    if p:\n",
    "        return p.group()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "print(expand_abbr(\"Welcome to Algriculture Bank China\", 'ABC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "圆括号 ( ) 组机制可与 findall() 结合使用。如果模式包含 2 个或更多圆括号组，则 findall() 会返回 *元组* 列表，而不是返回字符串列表。每个元组代表模式的一个匹配，该元组内是 group(1)、group(2) 数据。因此，如果电子邮件格式中添加 2 个圆括号组，则 findall() 会返回一个元组列表，每个元组长度为 2 都包含用户名和主机，例如 ('alice', 'google.com')。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alice', 'google.com'), ('bob', 'abc.com')]\n",
      "alice\n",
      "google.com\n",
      "bob\n",
      "abc.com\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "tuples = re.findall(r'([\\w\\.-]+)@([\\w\\.-]+)', str)\n",
    "print(tuples)  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n",
    "for tuple in tuples:\n",
    "    print(tuple[0])  ## username\n",
    "    print(tuple[1])  ## host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple alice@yo-yo-dyne.com, blah monkey bob@yo-yo-dyne.com blah dishwasher\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "## re.sub(pat, replacement, str) -- returns new string with all replacements,\n",
    "## \\1 is group(1), \\2 group(2) in the replacement\n",
    "print(re.sub(r'([\\w\\.-]+)@([\\w\\.-]+)', r'\\1@yo-yo-dyne.com', str))\n",
    "## purple alice@yo-yo-dyne.com, blah monkey bob@yo-yo-dyne.com blah dishwasher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 自然语言处理\n",
    "\n",
    "自然语言是指汉语、英语、法语等人们日常使用的语言，自然语言处理是指用计算机对自然语言的形、音、义等信息进行处理，即对字、词、句、篇章等进行输入、输出、识 别、分析、理解等一系列操作的过程。\n",
    "\n",
    "根据研究对象的不同，自然语言处理可以分为词法分析、句法分析和语义分析等内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 词语切分(word tokenization)\n",
    "\n",
    "即分词，是将句子切分成单词的过程。句子是单词的集合，对句子进行词语切分，本质上就是将一个句子分割成一个单词列表，该单词列表又可以重新还原为原句子。\n",
    "\n",
    "- 采用jiaba模块进行中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\车乾\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.349 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/是/一名/大学生/，/我/喜欢/自然语言/处理/。\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"我是一名大学生，我喜欢自然语言处理。\") \n",
    "print(\"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 采用NLTK模块进行英文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'a', 'college', 'student', '.', 'I', 'love', 'natural', 'language', 'processing', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"I am a college student. I love natural language processing.\"\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 词性标注（part-of-speech tagging）\n",
    "\n",
    "词性（part of speech, POS）是基于语法语境和词语作用的具体词汇分类，是词语的基本语法属性；\n",
    "\n",
    "词性标注，又称为词类标注或简称为标注，是指为分词结果中的每个单词标注一个正确的词性的过程，即确定每个词是名词、动词、形容词或者其他词性的过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "是 v\n",
      "一名 m\n",
      "大学生 n\n",
      "， x\n",
      "我 r\n",
      "喜欢 v\n",
      "自然语言 l\n",
      "处理 v\n",
      "。 x\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我是一名大学生，我喜欢自然语言处理。\") \n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 词义消歧\n",
    "\n",
    "词义消歧指的是确定待分析词语在文本中的含义的过程。词义消歧在文本理解的任务中极为重要，是句子和篇章语义理解的基础。\n",
    "\n",
    "- 以基于Lesk算法的词义消歧工具pywsd为例，展示词义消歧具体过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('depository_financial_institution.n.01')\n",
      "a financial institution that accepts deposits and channels the money into lending activities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "took 9.732271909713745 secs.\n"
     ]
    }
   ],
   "source": [
    "from pywsd.lesk import simple_lesk\n",
    "sent = 'I went to the bank to deposit my money.'\n",
    "ambiguous = 'bank'\n",
    "answer = simple_lesk(sent, ambiguous, pos='n')\n",
    "print(answer)\n",
    "print(answer.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 自然语言处理常用工具\n",
    "\n",
    "### 10.5.1 NLTK  <font color=Blue>(Self-learning)</font>\n",
    "\n",
    "NLTK 大概是最知名的Python自然语言处理工具了，全称\"Natural Language Toolkit\", 诞生于宾夕法尼亚大学，以研究和教学为目的而生，因此也特别适合入门学习。NLTK虽然主要面向英文，但是它的很多NLP模型或者模块是语言无关的，因此如果某种语言有了初步的Tokenization或者分词，NLTK的很多工具包是可以复用的。\n",
    "\n",
    "关于NLTK，网上已经有了很多介绍资料，当然首推的NLTK学习资料依然是官方出的在线书籍 [NLTK Book：Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit ](http://www.nltk.org/book/)，目前基于Python 3 和 NLTK 3 ，可以在线免费阅读和学习。\n",
    "\n",
    "请阅读本小节代码，**<font color=red>该部分代码不用运行！</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Adam, how are you?', 'I hope everything is going well.', 'Today is a good day, see you dude.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"Hello Adam, how are you? I hope everything is going well. Today is a good day, see you dude.\"\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Adam', ',', 'how', 'are', 'you', '?', 'I', 'hope', 'everything', 'is', 'going', 'well', '.', 'Today', 'is', 'a', 'good', 'day', ',', 'see', 'you', 'dude', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Hello Adam, how are you? I hope everything is going well. Today is a good day, see you dude.\"\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "print(porter_stemmer.stem('working'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('works'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize('playing',pos=\"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'does', 'the', 'fox', 'say']\n",
      "[('what', 'WDT'), ('does', 'VBZ'), ('the', 'DT'), ('fox', 'NNS'), ('say', 'VBP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text=nltk.word_tokenize('what does the fox say')\n",
    "print(text)\n",
    "print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.2 jieba\n",
    "\n",
    "jieba库是一款优秀的 Python 第三方中文分词库，支持三种分词模式：精确模式、全模式和搜索引擎模式，下面是三种模式的特点。\n",
    "\n",
    "- 精确模式：试图将语句最精确的切分，不存在冗余数据，适合做文本分析\n",
    "\n",
    "- 全模式：将语句中所有可能是词的词语都切分出来，速度很快，但是存在冗余数据\n",
    "\n",
    "- 搜索引擎模式：在精确模式的基础上，对长词再次进行切分\n",
    "\n",
    "**<font color=red>请阅读并运行本小节代码。</font>**\n",
    "\n",
    "#### 1. jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默认模式:  我/是/一名/武汉大学/的/学生\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"我是一名武汉大学的学生\")  # 使用默认模式，默认是精确模式\n",
    "print(\"默认模式: \",\"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 利用Jieba进行关键词提取\n",
    "\n",
    "关键词提取就是从文本里面把跟这篇文章意义最相关的一些词语抽取出来，在文献检索、自动文摘、文本聚类/分类等方面有着重要的应用。\n",
    "\n",
    "关键词提取算法一般分为有监督和无监督两类\n",
    "\n",
    "有监督的关键词提取方法主要是通过分类的方式进行，通过构建一个较为丰富和完善的词表，然后判断每个文档与词表中每个词的匹配程度，以类似打标签的方式，达到关键词提取的效果。优点是精度较高，缺点是需要大批量的标注数据，人工成本过高，并且词表需要及时维护。\n",
    "\n",
    "相比较而言，无监督的方法对数据的要求低，既不需要一张人工生成，维护的词表，也不需要人工标注语料辅助训练。目前比较常用的关键词提取算法都是基于无监督算法。如TF-IDF算法，TextRank算法和主题模型算法（包括LSA，LSI，LDA等）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于 TF-IDF 算法的关键词提取\n",
    "\n",
    "TF-IDF是一种数值统计方法，用于反映一个词对于预料中某篇文档的重要性，它的主要思想为：如果某个词在一篇文档中出现的频率高，即TF高；并且在其他文档中很少出现，即IDF高，则认为这个词具有很好的类别区分能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我校 0.3650310687908397\n",
      "自强 0.36010570737862596\n",
      "弘毅 0.3397889749526718\n",
      "校训 0.2773034698328244\n",
      "拓新 0.18251553439541984\n",
      "语出 0.17087980841068703\n",
      "求是 0.16727081943206107\n",
      "自强不息 0.16308094392519082\n",
      "武汉大学 0.14590644626137403\n",
      "中华民族 0.12336785834534353\n",
      "含义 0.11406043013648855\n",
      "伟大 0.1062369610119084\n",
      "不断进取 0.10082084329312978\n",
      "明诚 0.09772568979618321\n",
      "天行健 0.09552964344198472\n",
      "奋发向上 0.09382625755343511\n",
      "修学 0.09382625755343511\n",
      "好古 0.09382625755343511\n",
      "传统美德 0.0924344899442748\n",
      "校风 0.0924344899442748\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "sentence = '1993年，在广泛征求各方面意见的基础上，经校务委员会审议，武汉大学新校训定为：\\\n",
    "自强 弘毅 求是 拓新。“自强”语出《周易》“天行健、君子以自强不息”。意为自尊自重，不断自力图强，\\\n",
    "奋发向上。自强是中华民族的传统美德，成就事业当以此为训。我校最早前身为“自强学堂”，其名也取此意。\\\n",
    "“弘毅”出自《论语》“士不可以不弘毅，任重而道远”一语。意谓抱负远大，坚强刚毅。\\\n",
    "我校30年代校训“明诚弘毅”就含此一词。用“自强”、“弘毅”，既概括了上述含义，\\\n",
    "又体现了我校的历史纵深与校风延续。“求是”即为博学求知，努力探索规律，追求真理。\\\n",
    "语出《汉书》“修学好古，实事求是”。“拓新”，意为开拓、创新，不断进取。概言之，\\\n",
    "我校新校训的整体含义是： 继承和发扬中华民族自强不息的伟大精神，树立为国家的繁荣昌盛刻苦学习、\\\n",
    "积极奉献的伟大志向，以坚毅刚强的品格和科学严谨的治学态度，努力探求事物发展的客观规律，开创新局面，\\\n",
    "取得新成绩，办好社会主义的武汉大学，不断为国家作出新贡献。'\n",
    "\n",
    "keywords=jieba.analyse.extract_tags(sentence,topK=20,withWeight=True,allowPOS=())\n",
    "for item in keywords:\n",
    "    print(item[0],item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 基于 TextRank 算法的关键词提取\n",
    "\n",
    "此种算法的一个重要特点是可以脱离语料库的背景，仅对单篇文档进行分析就可以提取该文档的关键词。基本思想来源于Google的PageRank算法。这种算法是1997年，Google创始人拉里.佩奇和谢尔盖.布林在构建早期的搜索系统原型时提出的一种链接分析算法，基本思想有两条：\n",
    "\n",
    "    - 1）链接数量。一个网页被越多的其他网页链接，说明这个网页越重要\n",
    "    - 2）链接质量。一个网页被一个越高权值的网页链接，也能表明这个网页越重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "国家 1.0\n",
      "含义 0.9514975766301668\n",
      "校训 0.8831816220202372\n",
      "创新 0.7692786654850344\n",
      "客观规律 0.6586080643543306\n",
      "探求 0.6580889640584097\n",
      "历史 0.5969396515025892\n",
      "自强 0.591162600642535\n",
      "成绩 0.578783632054623\n",
      "取得 0.5695284955354087\n",
      "求知 0.5629593666958073\n",
      "探索 0.5608546033210623\n",
      "态度 0.5597483134160578\n",
      "奉献 0.5595424204402842\n",
      "局面 0.5572237414652758\n",
      "事物 0.5203076902458431\n",
      "校务 0.5201438592373493\n",
      "方面 0.5199791277209296\n",
      "审议 0.5190906744439646\n",
      "意见 0.5181603419662032\n"
     ]
    }
   ],
   "source": [
    "keywords = jieba.analyse.textrank(sentence, topK=20, withWeight=True, \\\n",
    "                                  allowPOS=('ns','n','vn','v'))\n",
    "for item in keywords:\n",
    "    print(item[0],item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.3 pyLTP  <font color=Blue>(Self-learning)</font>\n",
    "\n",
    "语言技术平台（Languange Technolog Platform, LTP）是由哈工大社会计算与信息检索中心研发的自然语言处理工具。提供了一系列中文自然语言处理工具，用户可以使用这些工具对于中文文本进行分词、词性标注、句法分析等等工作。从应用角度来看，LTP为用户提供了下列组件：\n",
    "\n",
    "- 针对单一自然语言处理任务，生成统计机器学习模型的工具\n",
    "- 针对单一自然语言处理任务，调用模型进行分析的编程接口\n",
    "- 使用流水线方式将各个分析工具结合起来，形成一套统一的中文自然语言处理系统\n",
    "- 系统可调用的，用于中文语言处理的模型文件\n",
    "- 针对单一自然语言处理任务，基于云端的编程接口\n",
    "\n",
    "pyltp 是 LTP 的 Python 封装，提供了分词，词性标注，命名实体识别，依存句法分析，语义角色标注的功能。\n",
    "\n",
    "请阅读本小节代码，**<font color=red>该部分代码不用运行！</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 利用PYLTP进行分句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyltp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceSplitter\n\u001b[0;32m      2\u001b[0m sents \u001b[38;5;241m=\u001b[39m SentenceSplitter\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m我喜欢自然语言处理。我也是！\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sents))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "from pyltp import SentenceSplitter\n",
    "sents = SentenceSplitter.split('我喜欢自然语言处理。我也是！')\n",
    "print ('\\n'.join(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 利用PYLTP进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\3948713506.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\3948713506.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m LTP_DATA_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLTP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mltp_data\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# ltp模型目录的路径\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cws_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LTP_DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcws.model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m#分词模型路径，模型名称为`cws.model`\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyltp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Segmentor\n\u001b[0;32m      6\u001b[0m segmentor \u001b[38;5;241m=\u001b[39m Segmentor()  \u001b[38;5;66;03m# 初始化实例\u001b[39;00m\n\u001b[0;32m      7\u001b[0m segmentor\u001b[38;5;241m.\u001b[39mload(cws_model_path)  \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  #分词模型路径，模型名称为`cws.model`\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(cws_model_path)  # 加载模型\n",
    "words = segmentor.segment('我喜欢自然语言处理')  # 分词\n",
    "print ('\\t'.join(words))\n",
    "segmentor.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 利用PYLTP进行词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\3314396065.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'      # ltp模型目录的路径\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\3314396065.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'      # ltp模型目录的路径\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m pos_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LTP_DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos.model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 词性标注模型路径，模型名称为`pos.model`\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyltp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Postagger\n\u001b[0;32m      7\u001b[0m postagger \u001b[38;5;241m=\u001b[39m Postagger() \u001b[38;5;66;03m# 初始化实例\u001b[39;00m\n\u001b[0;32m      8\u001b[0m postagger\u001b[38;5;241m.\u001b[39mload(pos_model_path)  \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = 'D:\\LTP\\ltp_data'      # ltp模型目录的路径\n",
    "pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')  \n",
    "# 词性标注模型路径，模型名称为`pos.model`\n",
    "from pyltp import Postagger\n",
    "postagger = Postagger() # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "words = ['我', '喜欢', '自然', '语言','处理']  # 分词结果\n",
    "postags = postagger.postag(words)  # 词性标注\n",
    "print ('\\t'.join(postags))\n",
    "postagger.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 利用PYLTP进行命名实体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\1679924204.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\1679924204.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m LTP_DATA_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLTP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mltp_data\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# ltp模型目录的路径\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ner_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LTP_DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mner.model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 命名实体识别模型路径，模型名称为`pos.model`\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyltp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NamedEntityRecognizer\n\u001b[0;32m      6\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m NamedEntityRecognizer() \u001b[38;5;66;03m# 初始化实例\u001b[39;00m\n\u001b[0;32m      7\u001b[0m recognizer\u001b[38;5;241m.\u001b[39mload(ner_model_path)  \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
    "ner_model_path = os.path.join(LTP_DATA_DIR, 'ner.model')  # 命名实体识别模型路径，模型名称为`pos.model`\n",
    "from pyltp import NamedEntityRecognizer\n",
    "recognizer = NamedEntityRecognizer() # 初始化实例\n",
    "recognizer.load(ner_model_path)  # 加载模型\n",
    "words = ['我', '喜欢', '自然', '语言','处理']\n",
    "postags = ['r', 'v','n','n', 'v']\n",
    "netags = recognizer.recognize(words, postags)  # 命名实体识别\n",
    "print ('\\t'.join(netags))\n",
    "recognizer.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 利用PYLTP进行依存句法分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\81100776.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\81100776.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m LTP_DATA_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLTP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mltp_data\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# ltp模型目录的路径\u001b[39;00m\n\u001b[0;32m      4\u001b[0m par_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LTP_DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparser.model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 依存句法分析模型路径，模型名称为`parser.model`\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyltp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parser\n\u001b[0;32m      6\u001b[0m parser \u001b[38;5;241m=\u001b[39m Parser() \u001b[38;5;66;03m# 初始化实例\u001b[39;00m\n\u001b[0;32m      7\u001b[0m parser\u001b[38;5;241m.\u001b[39mload(par_model_path)  \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
    "par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')  # 依存句法分析模型路径，模型名称为`parser.model`\n",
    "from pyltp import Parser\n",
    "parser = Parser() # 初始化实例\n",
    "parser.load(par_model_path)  # 加载模型\n",
    "words = ['我', '喜欢', '自然', '语言','处理']\n",
    "postags = ['r', 'v','n','n', 'v']\n",
    "arcs = parser.parse(words, postags)  # 句法分析\n",
    "print (\"\\t\".join(\"%d:%s\" % (arc.head, arc.relation) for arc in arcs))\n",
    "parser.release()  # 释放模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 利用PYLTP进行语义角色标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\2749813300.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
      "C:\\Users\\车乾\\AppData\\Local\\Temp\\ipykernel_18028\\2749813300.py:3: SyntaxWarning: invalid escape sequence '\\L'\n",
      "  LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyltp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m LTP_DATA_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLTP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mltp_data\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# ltp模型目录的路径\u001b[39;00m\n\u001b[0;32m      4\u001b[0m srl_model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LTP_DATA_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpisrl_win.model\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 语义角色标注模型目录路径，模型目录为`srl`。\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyltp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SementicRoleLabeller\n\u001b[0;32m      6\u001b[0m labeller \u001b[38;5;241m=\u001b[39m SementicRoleLabeller() \u001b[38;5;66;03m# 初始化实例\u001b[39;00m\n\u001b[0;32m      7\u001b[0m labeller\u001b[38;5;241m.\u001b[39mload(srl_model_path)  \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyltp'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "LTP_DATA_DIR = 'D:\\LTP\\ltp_data'  # ltp模型目录的路径\n",
    "srl_model_path = os.path.join(LTP_DATA_DIR, 'pisrl_win.model')  # 语义角色标注模型目录路径，模型目录为`srl`。\n",
    "from pyltp import SementicRoleLabeller\n",
    "labeller = SementicRoleLabeller() # 初始化实例\n",
    "labeller.load(srl_model_path)  # 加载模型\n",
    "words = ['我', '喜欢', '自然', '语言','处理']\n",
    "postags = ['r', 'v','n','n', 'v']\n",
    "# arcs 使用依存句法分析的结果\n",
    "roles = labeller.label(words, postags, arcs)  # 语义角色标注\n",
    "# 打印结果\n",
    "for role in roles:\n",
    "    print (role.index, \"\".join(\n",
    "        [\"%s:(%d,%d)\" % (arg.name, arg.range.start, arg.range.end) for arg in role.arguments]))\n",
    "labeller.release()  # 释放模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 上机实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 利用正则表达式，将“i am a college student, I am not a businessman.”中拼写错误的“i” 替换为“I”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a college student, I love whu. \n"
     ]
    }
   ],
   "source": [
    "text= \" i am a college student, i love whu. \"\n",
    "import re\n",
    "pattern = re.compile(r'(?:[^\\w]|\\b)i(?:[^\\w])')\n",
    "while True:\n",
    "    result = pattern.search(text)\n",
    "    if result:\n",
    "        if result.start(0) != 0:\n",
    "            text= text[:result.start(0)+1]+'I'+ text[result.end(0)-1:]\n",
    "        else:\n",
    "            text= text [:result.start(0)]+'I'+ text[result.end(0)-1:]\n",
    "    else:\n",
    "        break\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 句子“I love love wuhan university”中有单词重复的错误，利用正则表达式检查重复的单词并只保留一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I love wuhan university.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = ' I love love wuhan university.'\n",
    "pattern = re.compile(r'\\b(\\w+)(\\s+\\1){1,}\\b')\n",
    "matchResult = pattern.search(text)\n",
    "text = pattern.sub(matchResult.group(1), text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 利用 Jieba 分词对此句子进行分词和词性标注:“我是一名大学生，我来自武汉大学”。 学生可执行设计需要进行实验的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "是 v\n",
      "一名 m\n",
      "大学生 n\n",
      "， x\n",
      "我 r\n",
      "来自 v\n",
      "武汉大学 nt\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"我是一名大学生，我来自武汉大学\") \n",
    "for word, flag in words:\n",
    "    print('%s %s' % (word, flag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上机作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、字符串的函数应用\n",
    "\n",
    ">Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world with very little to distress or vex her.\n",
    "\n",
    "针对上述语料，请完成以下操作:\n",
    "\n",
    "(1) 统计上述文本中共有多少个单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 输出上述文本中所有长度为4个字母的单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 将上一步输出的单词分别以首字母大写、全大写、全小写的方式输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、正则表达式的应用\n",
    "\n",
    "(1) 编写正则表达式，匹配所有的有效的Python标识符集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 编写正则表达式，查找下面文本中所有处于单词开头位置的字母。\n",
    "\n",
    " >`Python is a great object-oriented, interpreted, and interactive programming language.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 编写正则表达式，查找下面文本中所有处于单词开头位置的数字。\n",
    " \n",
    " >`Pyth8on 7is a 3great 2object-oriented, inter4preted, 1an3d interactive programming 5language.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 编写程序，检测下列电子邮箱地址是否规范。符合规范的输出该邮箱地址，并提示其符合规范；对于不符合规范的邮箱地址，提示其不合规范，并提供`whu123@163.com`作为参考规范。\n",
    "   \n",
    "   >`email1: abc123@163com;    email2: abc321@123.com;    email3: bdssq@com;`\n",
    "    \n",
    "   >`email4: 2233198@acn.cn;   email5: bdad@dsa@qq.com    email6: wss321@222.c.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
